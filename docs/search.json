[
  {
    "objectID": "index.html#current-work",
    "href": "index.html#current-work",
    "title": "About",
    "section": "Current Work",
    "text": "Current Work\n\nBusiness Intelligence Engineer, Snap! Finance\n\nMy focus is on the Collections Department of the business, although lately I am assisting with the data migration of a LMS (Loan Management System). Saving money, making money, keeping the money flowing… everyday!\nManage dashboards that use R Shiny and are hosted on the company’s server, Posit Connect\nClean and prepare data from various sources (AWS S3, Presto/Postgre databases)\nAutomate reports (Anomaly detection, daily scripts, PowerPoints)"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Guy McAtee",
    "section": "Education",
    "text": "Education\n\nUtah Valley University\n\nBS Information Systems, Business Intelligence 2016-2020"
  },
  {
    "objectID": "index.html#what-can-i-do-for-you",
    "href": "index.html#what-can-i-do-for-you",
    "title": "Guy McAtee",
    "section": "What can I do for you?",
    "text": "What can I do for you?\nA question better suited for you, but I will list some things here:\n\nBuild and maintain ETL processes\n\nAirflow, Presto, PostgreSQL, Posit Connect (RStudio)\n\nBuild interactive and compelling visuals\n\nHighcharts, Plotly, GGPlot etc.\n\nBuild interactive Dashboards in little time\n\nRShiny, Graveler, BS4, ZenDash, Tableau\n\nAnalyze data and tell a story to help stakeholders understand the findings\nExperiment analysis (A/B testing, stats)\nProphet model forecasting"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Guy McAtee",
    "section": "",
    "text": "A question better suited for you, but I will list some things here:\n\nBuild and maintain ETL processes\n\nAirflow, Presto, PostgreSQL, Posit Connect (RStudio)\n\nBuild interactive and compelling visuals\n\nHighcharts, Plotly, GGPlot etc.\n\nBuild interactive Dashboards in little time\n\nRShiny, Graveler, BS4, ZenDash, Tableau\n\nAnalyze data and tell a story to help stakeholders understand the findings\nExperiment analysis (A/B testing, stats)\nProphet model forecasting\n\n\n\n\n\n\n\n\n\n\nMy focus is on the Collections Department of the business, although lately I am assisting with the data migration of a LMS (Loan Management System). Saving money, making money, keeping the money flowing… everyday!\nManage dashboards that use R Shiny and are hosted on the company’s server, Posit Connect\nClean and prepare data from various sources (AWS S3, Presto/Postgre databases)\nAutomate reports (Anomaly detection, daily scripts, PowerPoints)\n\n\n\n\n\n\n\n\nBS Information Systems, Business Intelligence 2016-2020"
  },
  {
    "objectID": "bring_current.html",
    "href": "bring_current.html",
    "title": "Bring Current Rates",
    "section": "",
    "text": "Choose a Plot Style\n\n\n\n\n\n\nHeatmap\n\n\n\n\n\nLine"
  },
  {
    "objectID": "bring_current.html#step-1-get-the-data",
    "href": "bring_current.html#step-1-get-the-data",
    "title": "Bring Current Rates",
    "section": "Step 1: Get the data",
    "text": "Step 1: Get the data"
  },
  {
    "objectID": "bring_current.html#step-2-write-a-function-to-produce-a-heatmap",
    "href": "bring_current.html#step-2-write-a-function-to-produce-a-heatmap",
    "title": "Bring Current Rates",
    "section": "Step 2: Write a function to produce a heatmap",
    "text": "Step 2: Write a function to produce a heatmap"
  },
  {
    "objectID": "bring_current.html#step-3-create-ui-elements",
    "href": "bring_current.html#step-3-create-ui-elements",
    "title": "Bring Current Rates",
    "section": "Step 3: Create UI elements",
    "text": "Step 3: Create UI elements"
  },
  {
    "objectID": "bring_current.html#steps",
    "href": "bring_current.html#steps",
    "title": "Bring Current Rates Demo",
    "section": "Steps",
    "text": "Steps\n\nSQL Query returning all new delinquencies and a column for recovered_ts\n\n# simplified for the sake of the demo\n bcr_data <- presto(\n   \"\n   SELECT\n     DATE(delinquency_ts AT TIME ZONE 'America/Denver') AS delinquency_dt\n     , DATE(recovered_ts AT TIME ZONE 'America/Denver') AS recovery_dt\n     , de.customer_application_id\n     , CASE WHEN recovered_ts IS NOT NULL THEN\n         DATE_DIFF('day',\n         DATE(delinquency_ts AT TIME ZONE 'America/Denver'),\n         DATE(recovered_ts AT TIME ZONE 'America/Denver'))\n         ELSE NULL\n       END AS days\n   FROM current.snapcollections__delinquency_event de\n   WHERE DATE(delinquency_ts AT TIME ZONE 'America/Denver') >= date '2020-01-01'\n \")\n\n\n\nSave in Pin (pins data stored on Posit Connect server)\n\npin_write(posit_board, bcr_data, \"bcr_pinned_data\")\n\n\n\nFunction for creating heatmap/line chart (contents of fxn shown)\n\nPals <- list()\n#loop through all levels 'columns' in input df and get mean and sd\nfor(i in levels(df$Age)) {\n  mm <- mean(df$value[df$Age == i])\n  msd <- sd(df$value[df$Age == i])\n  # if column is nd then white bg\n  if(i == 'New Delinquencies') {\n    pal <- list(\n      minColor = 'white',\n      maxColor = 'white'\n    )\n  } else {\n    pal <- list(\n      min = mm - (3 * msd),\n      max = mm + (3 * msd),\n      #color stops\n      stops = list(\n        list(0.15,'#FDE725'),\n        # list(0.16,'#5DC863'),\n        list(0.5,'#21908C'),\n        # list(0.84,'#3B528B'),\n        list(0.85,'#440154')\n      )\n    )\n  }\n  # create list of color palettes\n  Pals <- c(Pals,list(pal))\n}\n  \n  ##### highchart using hcdf data\n  sd_highchart() %>%\n    sdhc_title(text=paste0('Cumulative Bring Current Rates')) %>%\n    sdhc_subtitle(text = eval(myHS)) %>% \n    hc_add_series_list(\n      hcdf\n    ) %>%\n    hc_legend(\n      enabled = FALSE\n    ) %>%\n    hc_yAxis(\n      #show max - 16 rows of data\n      min = max(df$y) - 16,\n      max = max(df$y),\n      scrollbar = list(\n        enabled = FALSE\n      ),\n      categories = factor(unique(df$Cohort))\n    ) %>%\n    hc_xAxis(\n      opposite = TRUE,\n      categories = levels(df$Age)\n    ) %>%\n    hc_plotOptions(\n      series = list(\n        dataLabels = list(\n          overflow = 'none',\n          crop = TRUE,\n          enabled = TRUE,\n          #percentages and thousands comma on new delis\n          formatter = JS(\n            \"function() {\n              if (this.point.value == null) {\n                return ''\n              } else if (this.point.x > 0) {\n                return this.point.value + ' %'\n              } else {\n                return Highcharts.numberFormat(this.point.value, 0)\n              };\n            }\"\n          )        \n        )\n      )\n    ) %>% \n    hc_tooltip( # custom tooltip\n        formatter = JS(\n          \"function () {\n            if (this.point.value == null) {\n              return ''\n            } else if (this.point.x > 0) {\n              return 'BCR ' + this.point.value + ' %'\n            } else {\n              return 'New Delinquencies ' + Highcharts.numberFormat(this.point.value, 0)\n            };\n          }\"\n        )\n    )->p\n  # set color Axis to list of colors in Pals\n  p$x$hc_opts$colorAxis <- Pals\n\n\n\nLine chart using highcharts (contents of fxn shown)\n\n  # hard coding some variables typically used in reactive function\n  cohort_age = 0\n  hardship = \"Exclude\"\n  myRate = 'Cumulative'\n  \n  if(hardship == \"Exclude\") {\n    subtitle = 'Hardship accounts excluded'\n  } else {\n    subtitle = 'Hardship accounts included'\n  }\n  \n  if(myRate == 'Individual'){\n    myRate='BCRate'\n  }else{\n    myRate='BCRateCuml'\n  }\n  \n  # data frame of labels for Year Over Year view\n  my_labels <-  data.frame(\n    date_label = seq(\n      as.Date('2023-01-01'),\n      ceiling_date(Sys.Date(), 'year') - 1,\n      by='week'\n    ) + 1\n  ) %>% \n    mutate(\n      date_label = floor_date(date_label, 'week',week_start = 1),\n      week_num = week(date_label)\n    ) %>% filter(year(date_label)==\"2023\")\n  \n  bca_plot_data <- df %>%\n    na.omit() %>% \n    mutate(\n      year = year(Week),\n      week_num = week(Week),\n      week_actual = Week + weeks(as.integer(DelinquencyAge7) - 1),\n      bcr = ifelse(week_actual <= floor_date(Sys.Date(), 'week', week_start = 1), eval(sym(myRate)), NA)\n    ) %>% \n    filter(\n      year >= year(Sys.Date()) - 3\n    ) %>% \n    merge(\n      my_labels,\n      by = 'week_num'\n    )\n  \n  if (cohort_age == 0) {\n    my_filter <- paste0('Day ',cohort_age)\n    cohort_age_ref <- cohort_age\n  } else if(cohort_age == 10){\n    my_filter <- paste0('Week ',cohort_age,'+')\n    cohort_age_ref <- cohort_age - 1\n  } else {\n    my_filter <- paste0('Week ',cohort_age)\n    cohort_age_ref <- cohort_age - 1\n  }\n  \n  # data prep for highchart\n  hcdf <- bca_plot_data %>% \n    filter(\n      DelinquencyAge7 == eval(my_filter)\n    ) %>% \n    group_by(\n      name = year,\n      type = 'line',\n      color = case_when(\n        year == year(Sys.Date()) ~ snap_orange,\n        year == year(Sys.Date()) -1 ~ snap_blue,\n        year == year(Sys.Date()) -2 ~ snap_blue_light,\n        year == year(Sys.Date()) -3 ~ snap_grey_light,\n        year == year(Sys.Date()) -4 ~ snap_green,\n        year == year(Sys.Date()) -5 ~ snap_purple\n      ), \n      lineWidth = case_when(\n        year == year(Sys.Date()) ~ 3,\n        year == year(Sys.Date()) - 1 ~ 2,\n        year == year(Sys.Date()) - 2 ~ 2,\n        year ==year(Sys.Date())-3 ~ 2\n      )\n    ) %>% \n    do(data=list_parse(\n      data.frame(\n        x = datetime_to_timestamp(.$date_label),\n        y = round(.$bcr * 100, 2)\n      )\n    ))\n\nhighchart(type = 'stock') %>% \n    sdhc_title(text = paste0('Day 0 Bring Current Rates')) %>%\n    sdhc_subtitle(text = subtitle) %>% \n    hc_add_series_list(\n      hcdf\n    ) %>% \n    hc_xAxis(\n      plotLines = list(\n        list(\n          value = datetime_to_timestamp(covid_line), label = list(text='Covid 2020', color = snap_grey)\n        ),\n        list(\n          value = datetime_to_timestamp(stimulus_line), label = list(text='Stimulus 2020', align = 'left')\n        )\n      )\n    ) %>% \n    hc_tooltip(\n      valueSuffix='%'\n      ) %>% \n    hc_legend(enabled = TRUE) %>% \n    hc_navigator(enabled=FALSE) %>%\n    hc_rangeSelector(enabled=FALSE) %>%\n    hc_scrollbar(enabled=FALSE)   \n\n\n\nThese steps are combined with some Shiny reactive elements in dashboards for switching between options of charts/cohorts etc"
  },
  {
    "objectID": "prophet_model.html#steps",
    "href": "prophet_model.html#steps",
    "title": "Prophet Model Forecast Demo",
    "section": "Steps",
    "text": "Steps"
  },
  {
    "objectID": "prophet_model.html",
    "href": "prophet_model.html",
    "title": "Prophet Model Forecast Demo",
    "section": "",
    "text": "Registered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nWarning: replacing previous import 'httr::cache_info' by 'pins::cache_info'\nwhen loading 'snapdragon'\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nConnecting to rsconnect prod environment...\n\n\nConnecting to Posit Connect 2023.03.0 at <https://rstudio-connect.snapfinance.com>\n! Please use full name when reading a pin: \"gmcatee/forecast_cxn_auto\", not \"forecast_cxn_auto\".\n\n\nWarning: Deprecated function. Use the `create_axis` function."
  },
  {
    "objectID": "prophet_model.html#script-for-creating-a-prophet-forecast-for-dollars-collected-by-a-team-of-phone-agents",
    "href": "prophet_model.html#script-for-creating-a-prophet-forecast-for-dollars-collected-by-a-team-of-phone-agents",
    "title": "Prophet Model Forecast Demo",
    "section": "Script for creating a Prophet forecast for dollars collected by a team of phone agents",
    "text": "Script for creating a Prophet forecast for dollars collected by a team of phone agents\n\nDefine holidays, first and last day of month,\n\n# holidays \nmy_holidays <- presto(\n  \"\n  SELECT * FROM events\n  \"\n) %>% \n  mutate(\n    federal = if_else(holiday == 'New Year', 1, federal),\n    federal = if_else(holiday == \"President's Day\", 1, federal),\n    federal = if_else(holiday == 'Independence Day', 1, federal),\n    federal = if_else(holiday == 'Independence Day Observed', 1, federal),\n    federal = if_else(holiday == \"Veteran's Day\", 1, federal),\n    federal = if_else(holiday == \"Veteran's Day Observed\", 1, federal),\n    federal = if_else(holiday == 'Christmas', 1, federal),\n    federal = if_else(holiday == 'Christmas Observed', 1, federal),\n  )\n\nus_events <- my_holidays %>% \n  select(\n    -row.names,\n    -day_name,\n    -federal\n  )\n\n# paycycles and post holidays\nfom_eom_df <- data.frame(\n  date = seq(as.Date('2017-01-01'), Sys.Date()+365, by='day')\n) %>% \n  rename(\n    DATE = date\n  ) %>% \n  merge(\n    my_holidays %>% \n      rename(DATE = ds) %>% \n      filter(federal == 1) %>% \n      select(\n        DATE,\n        federal\n      ),\n    by = 'DATE',\n    all.x = TRUE\n  ) %>% \n  mutate(\n    dow = weekdays(DATE),\n    day_no = day(as.Date(DATE)),\n    federal = !(is.na(federal)),\n    eom = DATE == ceiling_date(DATE, 'month') - 1,\n    fom = DATE == floor_date(DATE, 'month'),\n    fbdom = case_when(\n      !(dow %in% c('Saturday','Sunday')) & fom == TRUE & federal == FALSE ~ TRUE,\n      lag(dow,1) == 'Sunday' & lag(fom,1) == TRUE & federal == FALSE ~ TRUE,\n      lag(dow,2) == 'Saturday' & lag(fom,2) == TRUE & federal == FALSE ~ TRUE,\n      lag(dow,2) == 'Sunday' & lag(fom,2) == TRUE & lag(federal,1) == TRUE & federal == FALSE ~ TRUE,\n      lag(dow,3) == 'Saturday' & lag(fom,3) == TRUE & lag(federal,1) == TRUE & federal == FALSE ~ TRUE,\n      TRUE ~ FALSE\n    ),\n    lbdom = case_when(\n      !(dow %in% c('Saturday','Sunday')) & eom == TRUE & federal == FALSE ~ TRUE,\n      !(dow %in% c('Saturday','Sunday')) & lead(eom,1) == TRUE & lead(federal,1) == TRUE & federal == FALSE ~ TRUE,\n      lead(dow,1) == 'Saturday' & lead(eom,1) == TRUE & federal == FALSE ~ TRUE,\n      lead(dow,2) == 'Sunday' & lead(eom,2) == TRUE & federal == FALSE ~ TRUE,\n      TRUE ~ FALSE\n    ),\n    mid_mo_payday = case_when(\n      day_no== 15 & !(dow %in% c('Saturday','Sunday')) ~ TRUE,\n      lag(day_no,1) == 15 & lag(dow,1) == 'Sunday' & federal == FALSE ~ TRUE,\n      lag(day_no,2) == 15 & lag(dow,2) == 'Saturday' & federal == FALSE ~ TRUE,\n      lag(day_no,2) == 15 & lag(dow,2) == 'Sunday' & lag(federal,1) == TRUE & federal == FALSE ~ TRUE,\n      lag(day_no,3) == 15 & lag(dow,3) == 'Saturday' & lag(federal,1) == TRUE & federal == FALSE ~ TRUE,\n      TRUE ~ FALSE\n    ),\n    post_holiday = case_when(\n      lag(federal,1) == TRUE & federal == FALSE & !(dow %in% c('Saturday','Sunday')) ~ TRUE,\n      dow == 'Monday' & lag(federal,3) ~ TRUE,\n      TRUE ~ FALSE\n    )\n  )\n\n\n\nGet historical performance\n\n# define number of days to forecast\nforecast_days <- 14\n\nproducts<-c('A','B')\nfor(my_product in products) {\n  print(my_product)\n\n if (my_product == 'A') {\n    my_operator = '='\n    cutoff_dt = as.Date('2017-01-01')\n    dels_dt = cutoff_dt - 14\n  } else {\n    my_operator = '<>'\n    cutoff_dt = as.Date('2019-01-01')\n    dels_dt = cutoff_dt - 14\n  }\n  \n  # get other forecasted data of delinquencies each day to be used as addtl regressor\n  dels_future <- if(my_product == 'A'){\n    pin_get('active_dels_pin', 'rsconnect')$A_cxn %>% rename(ds = day)\n  }else{\n    pin_get('active_dels_pin', 'rsconnect')$B_cxn %>% rename(ds = day)\n  }\n\n    if(my_product == 'A'){\n      cxn_vol <- presto(paste0(\n        \"\n          SELECT ca.payment_dt AS ds\n            , SUM(CAST(payment_amount AS DOUBLE)) AS y\n          FROM payment_data ca\n          WHERE ca.arrangement_status = 'VERIFIED'\n            AND ca.payment_dt >= date '\",cutoff_dt,\"'\n            AND product_type \",my_operator,\" 'A'\n          GROUP BY ca.payment_dt\n        \"\n      )) \n    \n      third_p<-presto(paste0(\n        \"\n          SELECT\n            cat.effective_dt as ds\n            , SUM(CAST(credit_amount AS DOUBLE)) as y\n          FROM transaction_data cat\n          LEFT JOIN accounts ca \n            ON ca.id = cat.account_id\n          WHERE cat.posted_user_id = 12345 --this is third_p id\n            --and 'type' = 'REGULAR_PAYMENT'\n            AND cat.voided_ts is null \n            AND cat.return_reason is null\n            AND cat.effective_dt >= date '2021-06-21'\n            AND cat.effective_dt < current_date\n            AND ca.product_type \",my_operator,\" 'A'\n          GROUP BY cat.effective_dt\n          \"\n    ))\n\n      coll_vol_daily<-cxn_vol %>% rbind(third_p) %>% group_by(ds) %>% summarise(y=sum(y))\n    }else{ # vol for B\n      cxn_vol <- presto(paste0(\n        \"\n          SELECT ca.payment_dt AS ds\n            , SUM(CAST(payment_amount AS DOUBLE)) AS y\n          FROM payments_prod ca\n          WHERE ca.arrangement_status = 'VERIFIED'\n            AND ca.payment_dt >= date '\",cutoff_dt,\"'\n            AND product_type \",my_operator,\" 'A'\n          GROUP BY ca.payment_dt\n        \"\n      ))\n      \n      coll_vol_daily<-cxn_vol %>% group_by(ds) %>% summarise(y=sum(y))\n    }\n\n# prophet for each day -----------------------------------------------------------------\n  days<-0:6\n  DF_all<-data.frame()\n  m_all<-list()\n  forecast_all<-data.frame()\n\n# loop through each day of the week and save forecast to forecast_all\n  for (day in days) {\n  \n    message(paste0(\"starting wday: \", day))\n      \n    mod_coll_data <- coll_vol_daily %>% \n      filter(\n        ds >= as.Date(cutoff_dt)\n      ) %>% \n      mutate(\n        ds = as.Date(ds),\n        dow = weekdays(ds),\n        wday = wday(ds) - 1, # for monday as 0 first day of week\n        month = months(ds),\n        year = year(ds)\n      ) %>% \n      merge(\n        fom_eom_df %>% rename(ds = DATE) %>% select(-dow),\n        by = 'ds',\n        all.x = TRUE\n      ) %>% \n      mutate(\n        saturday = dow == 'Saturday',\n        monday = dow == 'Monday',\n        thursday = dow == 'Thursday',\n        friday = dow == 'Friday',\n        taxseason = week(ds) >= 5 & week(ds) <= 11\n      ) %>% \n      filter(\n        ds < Sys.Date()\n        & !ds %in% c(\n          as.Date('2020-04-15')\n        )\n        & wday == {{ day }}\n      )\n    \n    # future data frame\n    \n    future_append <- data.frame(\n      ds = seq.Date(as.Date(min(mod_coll_data$ds)) ,(as.Date(my_end_date) + forecast_days), by = '1 day') %>%\n        format(\"%Y-%m-%d\") %>%\n        as.Date()\n    ) %>% \n      merge(\n        fom_eom_df %>% \n          mutate(\n            ds = DATE %>% format(\"%Y-%m-%d\") %>% as.Date()\n          ),\n        by = 'ds',\n        all.x = TRUE\n      )  %>% \n      mutate(\n        saturday = dow == 'Saturday',\n        monday = dow == 'Monday',\n        friday = dow == 'Friday',\n        thursday = dow == 'Thursday',\n        taxseason = week(ds) >= 5 & week(ds) <= 11,\n        wday = wday(ds)-1 # for monday as first dow\n      ) %>%\n      merge(\n        dels_future, all = TRUE\n      ) %>% filter(wday == {{ day }})\n    \n    # forecast variables\n    \n    holidayDF = us_events\n    additional_regressors = c(\n      'federal',\n      'post_holiday',\n      'fbdom',\n      'lbdom',\n      'mid_mo_payday',\n      'taxseason',\n      'monday',\n      'friday',\n      'saturday',\n      'delinquencies'#number of active delinquencies\n    ) \n    additional_future_data = list(future_append)\n    interval.width = .8\n    growth_model = 'linear'\n    # growth_model = 'logistic'\n    response_cap = NA\n    response_floor = 0\n    \n    # forecast df ####\n    DF <- mod_coll_data %>% \n      filter(ds <= my_end_date) %>% \n      merge(\n        holidayDF %>% \n          mutate(ds = as.Date(ds %>% format(\"%Y-%m-%d\"))),\n        by = 'ds',\n        all.x = TRUE\n      ) %>% \n      merge(\n        dels_future %>% filter(ds>=as.Date(cutoff_dt)), by = 'ds'\n      ) %>%\n      mutate(\n        cap = response_cap,\n        floor = response_floor\n      ) %>% \n      select(\n        -holiday,\n        -lower_window,\n        -upper_window,\n      ) %>% \n      mutate_if(is.numeric, funs(ifelse(is.na(.), 0, .)))\n    \n    end_date = as.Date(my_end_date)\n    if(is.na(response_cap)) {\n      response_cap = max(DF$y) + 6*(sd(DF$y))\n    }\n    \n    # model setup and additional regressors ####\n    m <- prophet(\n      seasonality.mode = \"multiplicative\"\n      , growth = growth_model # only way to forecast with saturating min or max\n      , holidays = holidayDF %>% filter(as.Date(ds) <= end_date)\n      , interval.width = interval.width\n      , daily.seasonality=FALSE\n      , yearly.seasonality = 13\n      , weekly.seasonality = 3\n    )\n    \n    # add user defined regressors\n    lar <- length(additional_regressors)\n    if(lar > 0) {\n      for(i in 1:lar) {\n        m = add_regressor(m, additional_regressors[i])\n      }\n    }\n\n    m$extra_regressors$saturday$prior.scale <- 10\n    # active dels mode\n    m$extra_regressors$delinquencies$mode <- 'multiplicative'#'additive'\n    \n    # model fit \n    m = fit.prophet(m, DF)\n    \n    # forecast ####\n    # create future data frame on which to run the forecast\n    future <- make_future_dataframe(m, periods = 14) %>% \n      mutate(ds = as.Date(ds %>% format(\"%Y-%m-%d\"))) %>% \n      left_join(\n        holidayDF %>% mutate(ds = as.Date(ds %>% format(\"%Y-%m-%d\"))),\n        by = 'ds'\n      ) %>% \n      filter(\n        wday(ds)-1 == {{ day }}\n      ) %>% \n      mutate(\n        cap = response_cap,\n        floor = response_floor\n      ) %>% \n      select(\n        -holiday,\n        -lower_window,\n        -upper_window\n      ) %>%\n      mutate_if(is.numeric, funs(ifelse(is.na(.), 0, .)))\n    \n    # merge additional future data frames\n    if (length(additional_future_data) > 0) {\n      for(i in 1:length(additional_future_data)) {\n        future <- future %>% \n          merge(\n            additional_future_data[i][[1]],\n            by = 'ds',\n            all.x = TRUE\n          ) %>% \n          mutate_if(is.numeric, funs(ifelse(is.na(.), 0, .)))\n      }\n      \n      future <- future %>% filter(!is.na(federal))\n    }\n    \n    forecast <- predict(m, future, mcmc.samples = 50)\n    # forecast$yhat\n    # dyplot.prophet(m_all,forecast_all)\n    eval(parse_expr(paste0(\"forecast_\",day,\"=forecast\")))\n    message(paste0(\"forecast saved for wday: \", day))     \n    \n    #add days data to all data frame\n    DF_all <- DF_all %>% rbind(DF)\n    m_all <- m_all %>% append(m) #list\n    forecast_all <- forecast_all %>% rbind(forecast)\n  }\n  \n  # output linear model data\n    a1 <- \n      DF_all %>%\n      group_by(day = as.Date(floor_date(ds, \"day\"))) %>%\n      summarise(\n        Actual = sum(y)\n      )\n    \n    b1 <-\n      forecast_all %>%\n      group_by(day = as.Date(floor_date(ds, \"day\"))) %>%\n      summarise(\n        Forecast = round(sum(yhat))\n        ,LowForecast = round(sum(yhat_lower),0)\n        ,HighForecast = round(sum(yhat_upper),0)\n      ) \n  # combine fcst and actuals df  \n    outputDF <- b1 %>% left_join(a1)\n      \n      normHigh_name = paste0('normHigh',as.character(interval.width))\n      normLow_name = paste0('normLow',as.character(interval.width))\n      \n      outputDF <- outputDF %>% \n        mutate(\n          Ratio = outputDF$Actual / outputDF$Forecast,\n          Uncertainty = interval.width,\n          Residual = outputDF$Actual - outputDF$Forecast,\n          !! normHigh_name := outputDF$HighForecast - outputDF$Forecast,\n          !! normLow_name := outputDF$LowForecast - outputDF$Forecast\n        )\n      \n      outputDF$dow = weekdays(outputDF$day)\n      \n  # this week\n    if (offset_bool == FALSE) {\n      my_filter = expr(\n        # day >= ceiling_date(Sys.Date(), 'week', week_start = 1)\n        # & day < ceiling_date(Sys.Date(), 'week', week_start = 1) + 7\n        floor_date(day,'week',week_start =1) == max(floor_date(day,'week',week_start =1)-7)\n      )\n    } else {\n      my_filter = expr(\n        day >= floor_date(Sys.Date(), 'week', week_start = 1) - (week_offset)\n        & day < ceiling_date(Sys.Date(), 'week', week_start = 1) - (week_offset)\n      )\n    }\n  \n  weekly_forecast_data <- outputDF %>%\n    filter(\n      eval(my_filter)\n      # day < '2022-01-24'\n    ) %>%\n    mutate(\n      week = floor_date(day, 'week', week_start = 1),\n      product = my_product\n    ) %>% \n    rename(\n      forecast = Forecast,\n      low_forecast = LowForecast,\n      high_forecast = HighForecast\n    ) %>% \n    select(\n      product,\n      week,\n      day,\n      dow,\n      forecast,\n      low_forecast,\n      high_forecast\n    ) %>% \n    mutate(\n      week = as.character(week)\n      , day = as.character(day)\n      , forecast = as.double(forecast)\n      , low_forecast = as.double(low_forecast)\n      , high_forecast = as.double(high_forecast)\n    )\n    \n  if(test_code == TRUE){\n    \n  }else if(test_code == FALSE){\n    \n    # get current pin\n    pin<-pin_get(\"forecast_cxn_auto\",board=\"rsconnect\")\n    \n    # add new weekly forecast to the pin\n    if(my_product=='A'){\n      pin$AForecast <- pin$AForecast %>% rbind(weekly_forecast_data)\n      \n      # re-pin the data\n    pin(pin, \"forecast_cxn_auto\", board=\"rsconnect\")\n    \n    prior_forecast <- pin_get(\"forecast_cxn_auto\", \"rsconnect\")$AForecast %>%\n      arrange(\n        day\n      ) %>%\n      filter(\n        week == floor_date(max(week)-1, 'week', week_start = 1)\n      )\n    \n    # eval(parse_expr(paste0(my_product,'_prio_forecast_data=prior_forecast')))\n    \n    }else{\n      pin$BForecast <- pin$BForecast %>% rbind(weekly_forecast_data)\n      \n      # re-pin the data\n      pin(pin, \"forecast_cxn_auto\", board=\"rsconnect\")\n      \n      prior_forecast <- pin_get(\"forecast_cxn_auto\", \"rsconnect\")$BForecast %>%\n        arrange(\n          day\n        ) %>%\n        filter(\n          week == floor_date(max(week) - 1, 'week', week_start = 1)\n        )\n    }\n    \n    # print out weekly forecast\n    paste0(my_product,' Forecast: $',sum(weekly_forecast_data$forecast)) %>% print()\n    paste0(my_product,' Low Forecast: $',sum(weekly_forecast_data$low_forecast)) %>% print()\n    paste0(my_product,' High Forecast: $',sum(weekly_forecast_data$high_forecast)) %>% print()\n    \n    # print out prior weekly forecast\n    paste0(my_product,' Prior Forecast: $',sum(prior_forecast$forecast)) %>% print()\n    paste0(my_product,' Prior Low Forecast: $',sum(prior_forecast$low_forecast)) %>% print()\n    paste0(my_product,' Prior High Forecast: $',sum(prior_forecast$high_forecast)) %>% print()\n    \n  }\n  \n}\n\n\n\nStore forecast and actuals in pin\n\nAForecast <- pin_get(\"forecast\",\"rsconnect\")$AForecast\n\ncxn_A_actual <- presto(\n  \"\n  SELECT ca.payment_dt AS day\n    , SUM(CAST(payment_amount AS DOUBLE)) AS actual\n  FROM snap_analytics.snapanalytics.collections_arrangements_automated ca\n  WHERE ca.arrangement_status = 'VERIFIED'\n    AND ca.payment_dt >= date '2020-06-21'\n    AND product_type = 'A'\n  GROUP BY ca.payment_dt\n\"\n) \n# week of 6/21/21 we decided to include third_p\nthird_p <- presto(\n  \"\n  SELECT\n    effective_dt as day\n    , SUM(CAST(credit_amount AS DOUBLE)) as actual\n  FROM transactions cat\n  WHERE cat.posted_user_id = 12345 --this is third_p id\n    --and 'type' = 'REGULAR_PAYMENT'\n    and cat.voided_ts is null \n    and cat.return_reason is null\n  -- the week we decided to start including third_p in the actuals\n    and effective_dt >=date '2021-06-21'\n    and effective_dt < current_date\n  GROUP BY effective_dt\n\")\n\nAActual<-cxn_A_actual %>% rbind(third_p) %>% group_by(day) %>% summarise(actual=sum(actual))\n\n\n#get pin\nforecastData <- pins::pin_get(\"forecast\", board = \"rsconnect\")\n\n#update data\nforecastData$AForecast <- AForecast\nforecastData$AActual <- AActual\n\nBActual <- presto(paste0(\n        \"\n          SELECT ca.payment_dt AS day\n            , SUM(CAST(payment_amount AS DOUBLE)) AS actual\n          FROM snap_analytics.snapanalytics.collections_arrangements ca\n          WHERE ca.arrangement_status = 'VERIFIED'\n            AND ca.payment_dt >= date '2019-01-01'\n            AND product_type != 'A'\n          GROUP BY ca.payment_dt\n        \"\n      ))\nBForecast <- pin_get(\"forecast\",\"rsconnect\")$BForecast\nforecastData$BForecast <- BForecast\nforecastData$BActual <- BActual\n\n#update pin with updated data\npins::pin(forecastData, name = 'forecast', board = 'rsconnect')"
  },
  {
    "objectID": "prophet_model.html#plot-created-with-highcharts-and-table-with-reactable",
    "href": "prophet_model.html#plot-created-with-highcharts-and-table-with-reactable",
    "title": "Prophet Model Forecast Demo",
    "section": "Plot created with highcharts and table with Reactable",
    "text": "Plot created with highcharts and table with Reactable"
  }
]